{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stelios191/Image-and-Video-Preprocessing-from-Scratch/blob/main/Image_and_Video_Preprocessing_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25b7fe0d-ef66-4c96-91b3-c91e2ad33cad",
      "metadata": {
        "id": "25b7fe0d-ef66-4c96-91b3-c91e2ad33cad"
      },
      "outputs": [],
      "source": [
        "pip install opencv-python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1edfda4d-78f1-41a7-b3a1-90c0053c15bf",
      "metadata": {
        "id": "1edfda4d-78f1-41a7-b3a1-90c0053c15bf"
      },
      "source": [
        "Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e944d8d1-497c-4c4f-9472-3250c407c752",
      "metadata": {
        "id": "e944d8d1-497c-4c4f-9472-3250c407c752"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af9dd3f6-c93d-4ff8-aa02-ea1d7cb18937",
      "metadata": {
        "id": "af9dd3f6-c93d-4ff8-aa02-ea1d7cb18937"
      },
      "source": [
        "Read and show the image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb3ddb66-54f7-471c-a00f-6005e0dcf4bb",
      "metadata": {
        "id": "fb3ddb66-54f7-471c-a00f-6005e0dcf4bb"
      },
      "source": [
        "input the image that contains my name written in Arial, point 72, capital letters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9ab1e3f-edf7-4db0-bcfb-1f91a59b1021",
      "metadata": {
        "id": "f9ab1e3f-edf7-4db0-bcfb-1f91a59b1021"
      },
      "outputs": [],
      "source": [
        "im = cv2.imread(\"cw1.png\")\n",
        "plt.imshow(im)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "110e022c-a667-434e-9d3d-4b0cbb07903c",
      "metadata": {
        "id": "110e022c-a667-434e-9d3d-4b0cbb07903c"
      },
      "source": [
        "Image Atrributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "467fd8a4-0ecc-4023-a8e1-9768e3d2ece4",
      "metadata": {
        "id": "467fd8a4-0ecc-4023-a8e1-9768e3d2ece4"
      },
      "outputs": [],
      "source": [
        "# Read in image\n",
        "cw = cv2.imread(\"cw1.png\", 1)\n",
        "\n",
        "# print the size  of image\n",
        "print(\"Image size (H, W, C) is:\", cw.shape)\n",
        "\n",
        "# print data-type of image\n",
        "print(\"Data type of image is:\", cw.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d16700b-ac14-4589-8bde-750a96aa2e17",
      "metadata": {
        "id": "6d16700b-ac14-4589-8bde-750a96aa2e17"
      },
      "source": [
        "Write a function that takes as input an image I, rotates it by an angle θ1 and horizontally skews it by\n",
        "an angle, θ2. Write the matrix formulation for image rotation R(.) and skewing S(.). Define all the\n",
        "variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a50dd53e-681f-4617-a4b9-a780caf6d0c7",
      "metadata": {
        "id": "a50dd53e-681f-4617-a4b9-a780caf6d0c7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def ICV_rotate(image, rotation_angle_degrees, fill_value=0):\n",
        "    theta = math.radians(rotation_angle_degrees)\n",
        "    # Compute the cosine and sine of the rotation angle\n",
        "    cos_theta = math.cos(theta)\n",
        "    sin_theta = math.sin(theta)\n",
        "    #Original image dimensions\n",
        "    orig_height, orig_width = image.shape[:2]\n",
        "    orig_center_y, orig_center_x = orig_height // 2, orig_width // 2\n",
        "    # Compute the bounding box of the new image\n",
        "    new_width = int(abs(orig_height * sin_theta) + abs(orig_width * cos_theta))\n",
        "    new_height = int(abs(orig_height * cos_theta) + abs(orig_width * sin_theta))\n",
        "    # an empty image for the output with the new dimensions\n",
        "    rotated_image = np.full((new_height, new_width, image.shape[2]), fill_value, dtype=image.dtype)\n",
        "    #New image center\n",
        "    new_center_x, new_center_y = new_width // 2, new_height // 2\n",
        "\n",
        "    # Perform rotation\n",
        "    for h in range(new_height):\n",
        "        for w in range(new_width):\n",
        "            # Apply the inverse rotation matrix to get the original coordinates\n",
        "            x_orig = (cos_theta * (h - new_center_x) + sin_theta * (h - new_center_y)) + orig_center_x\n",
        "            y_orig = (-sin_theta * (h - new_center_x) + cos_theta * (h - new_center_y)) + orig_center_y\n",
        "            # Checks the coordinates if are within the boundaries\n",
        "            if 0 <= x_orig < orig_width and 0 <= y_orig < orig_height:\n",
        "                # Assign the pixel value from the original image to the rotated image\n",
        "                rotated_image[h, w] = image[int(y_orig), int(x_orig)]\n",
        "    return rotated_image\n",
        "\n",
        "def ICV_skew(image, skew_angle_degrees, fill_value=0):\n",
        "    skew_angle_radians = math.radians(skew_angle_degrees)\n",
        "    skew_offset = abs(image.shape[0] * np.tan(skew_angle_radians))\n",
        "    # Compute the new width to accommodate the skew\n",
        "    new_width = int(image.shape[1] + skew_offset)\n",
        "    # Create an empty image with the new dimensions\n",
        "    skewed_image = np.full((image.shape[0], new_width, image.shape[2]), fill_value, dtype=image.dtype)\n",
        "    # Skew transformation\n",
        "    for y in range(image.shape[0]):\n",
        "        for x in range(image.shape[1]):\n",
        "            # Apply the skew transformation to the x\n",
        "            new_x = int(x + y * np.tan(skew_angle_radians))\n",
        "\n",
        "            # Assign the original pixel value to the new coordinates in the skewed image\n",
        "            skewed_image[y, new_x] = image[y, x]\n",
        "    return skewed_image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c84af0c-bf7a-48d0-9fe5-886456f4312e",
      "metadata": {
        "id": "0c84af0c-bf7a-48d0-9fe5-886456f4312e"
      },
      "source": [
        "Rotate clockwise\n",
        "the image you created by 30, 60, 120 and -50 degrees. Skew the same image by 10, 40 and 60\n",
        "degrees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dae3c08e-829a-4c27-94e3-a48c1b93543e",
      "metadata": {
        "id": "dae3c08e-829a-4c27-94e3-a48c1b93543e"
      },
      "outputs": [],
      "source": [
        "# Rotate images\n",
        "rotated_image_30 = ICV_rotate(cw, 30)\n",
        "rotated_image_60 = ICV_rotate(cw, 60)\n",
        "rotated_image_120 = ICV_rotate(cw, 120)\n",
        "rotated_image_minus = ICV_rotate(cw, -50)\n",
        "\n",
        "# Display the rotated images\n",
        "plt.figure()\n",
        "plt.title('Rotated by 30 degrees')\n",
        "plt.imshow(rotated_image_30)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Rotated by 60 degrees')\n",
        "plt.imshow(rotated_image_60)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Rotated by 120 degrees')\n",
        "plt.imshow(rotated_image_120)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Rotated by -50 degrees')\n",
        "plt.imshow(rotated_image_minus)\n",
        "plt.show()\n",
        "\n",
        "# Skew images\n",
        "skewed_image_10 = ICV_skew(cw, 10)\n",
        "skewed_image_40 = ICV_skew(cw, 40)\n",
        "skewed_image_60 = ICV_skew(cw, 60)\n",
        "\n",
        "# Display the skewed images\n",
        "plt.figure()\n",
        "plt.title('Skewed by 10 degrees')\n",
        "plt.imshow(skewed_image_10)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Skewed by 40 degrees')\n",
        "plt.imshow(skewed_image_40)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Skewed by 60 degrees')\n",
        "plt.imshow(skewed_image_60)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5834007-d71f-4047-808e-ec5f99a1b8bd",
      "metadata": {
        "id": "c5834007-d71f-4047-808e-ec5f99a1b8bd"
      },
      "source": [
        "Rotate the image by θ1 = 20 clockwise and then skew the result by θ2 = 50."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c28e615b-6274-4dbe-a0e4-ea4a96b04ccd",
      "metadata": {
        "id": "c28e615b-6274-4dbe-a0e4-ea4a96b04ccd"
      },
      "outputs": [],
      "source": [
        "# Rotate the image by θ1 = 20 degrees clockwise\n",
        "rotated_image_20 = ICV_rotate(cw, 20)\n",
        "\n",
        "# Skew the rotated image by θ2 = 50 degrees\n",
        "skewed_image_50 = ICV_skew(rotated_image_20, 50)\n",
        "\n",
        "# Display the rotated and skewed image\n",
        "plt.figure()\n",
        "plt.title('Rotated by 20 degrees and skewed by 50 degrees')\n",
        "plt.imshow(skewed_image_50)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f325248-6197-499f-bfe8-62622d871019",
      "metadata": {
        "id": "3f325248-6197-499f-bfe8-62622d871019"
      },
      "source": [
        "Skew the image by θ2 = 50 and then rotate the result by θ1 = 20 clockwise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f323b6-72fd-4013-aef5-f2f2b7177376",
      "metadata": {
        "id": "d8f323b6-72fd-4013-aef5-f2f2b7177376"
      },
      "outputs": [],
      "source": [
        "# Skew the image by θ2 = 50 degrees\n",
        "skewed_image = ICV_skew(cw, 50)\n",
        "\n",
        "# Rotate the skewed image by θ1 = 20 degrees clockwise\n",
        "rotated_image = ICV_rotate(skewed_image_50, 20)\n",
        "\n",
        "# Display the skewed and rotated image\n",
        "plt.figure()\n",
        "plt.title('Skewed by 50 degrees and rotated by 20 degrees clockwise')\n",
        "plt.imshow(rotated_image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b75389e-37ef-4fb4-b05b-c8c6cfef72c6",
      "metadata": {
        "id": "1b75389e-37ef-4fb4-b05b-c8c6cfef72c6"
      },
      "source": [
        "2) Convolution. (Use Dataset A)\n",
        "Convolution provides a way of multiplying two arrays to produce a third array. Depending on the designed\n",
        "filter and the intended effect, the kernel can be a matrix of dimensions, for example, 3x3, 5x5 or 7x7.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7ccb230-3c1d-4f9e-adbe-f51b973c4b75",
      "metadata": {
        "id": "e7ccb230-3c1d-4f9e-adbe-f51b973c4b75"
      },
      "source": [
        "a) Code a function that takes an input image, performs convolution with a given kernel, and returns the\n",
        "resulting image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1iM1pBvnIOir",
      "metadata": {
        "id": "1iM1pBvnIOir"
      },
      "outputs": [],
      "source": [
        "def ICV_convolution(image: np.array, kernel: np.array, padding='valid'):\n",
        "    image_height, image_width, num_channels = image.shape\n",
        "\n",
        "    kernel_height, kernel_width = kernel.shape\n",
        "    padding_height, padding_width = 0, 0\n",
        "\n",
        "    if padding == 'same':\n",
        "        padding_height = kernel_height // 2\n",
        "        padding_width = kernel_width // 2\n",
        "        padded_height = image_height + 2 * padding_height\n",
        "        padded_width = image_width + 2 * padding_width\n",
        "        padded_image = np.zeros((padded_height, padded_width, num_channels))\n",
        "        padded_image[padding_height:-padding_height, padding_width:-padding_width, :] = image\n",
        "    else:\n",
        "        padded_image = image\n",
        "\n",
        "    # Compute dimensions for the output image\n",
        "    output_height = image_height + 2 * padding_height - kernel_height + 1\n",
        "    output_width = image_width + 2 * padding_width - kernel_width + 1\n",
        "    # Initialize the output image with zeros\n",
        "    convolved_image = np.zeros((output_height, output_width, num_channels))\n",
        "\n",
        "    # Perform convolution by sliding the kernel over the image\n",
        "    for row in range(output_height):\n",
        "        for col in range(output_width):\n",
        "            for channel in range(num_channels):\n",
        "                # Extract the corresponding image patch\n",
        "                image_patch = padded_image[row:row+kernel_height, col:col+kernel_width, channel]\n",
        "                convolved_image[row, col, channel] = np.sum(image_patch * kernel)\n",
        "    # Clip pixel values\n",
        "    convolved_image = np.clip(convolved_image, 0, 255)\n",
        "    return convolved_image.astype(np.uint8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89f7e0fe-467b-419b-a89b-0526456792cb",
      "metadata": {
        "id": "89f7e0fe-467b-419b-a89b-0526456792cb"
      },
      "source": [
        " Design a convolution kernel that computes, for each pixel, the average intensity value in a 3x3 region.\n",
        "Use this kernel and the filtering function above, and save the resulting image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0a2350f-561f-41d1-a963-33df5ec992a9",
      "metadata": {
        "id": "f0a2350f-561f-41d1-a963-33df5ec992a9"
      },
      "outputs": [],
      "source": [
        "average_kernel = np.ones((3, 3)) / 9\n",
        "image = cv2.imread ('car-1.jpg')\n",
        "\n",
        "# Perform convolution and save the output image.\n",
        "output_image = ICV_convolution(image, average_kernel)\n",
        "cv2.imwrite('average_intensity_image.png', output_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uLNw1q_9jk25",
      "metadata": {
        "id": "uLNw1q_9jk25"
      },
      "source": [
        "Use the kernels provided below, apply the filtering function and save the resulting images. Comment\n",
        "on the effect of each kernel.\n",
        "kernel A\n",
        "1 2 1\n",
        "2 4 2\n",
        "1 2 1\n",
        "kernel B\n",
        "0 1 0\n",
        "1 -4 1\n",
        "0 1 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbffeb86-d605-4ef1-ab63-736e8dd33c51",
      "metadata": {
        "id": "cbffeb86-d605-4ef1-ab63-736e8dd33c51"
      },
      "outputs": [],
      "source": [
        "kernel_A = np.array([[1,2,1],\n",
        "                     [2,4,2],\n",
        "                     [1,2,1]])/9\n",
        "\n",
        "kernel_B = np.array([[0,1,0],\n",
        "                     [1,-4,1],\n",
        "                     [0,1,0]])\n",
        "\n",
        "# Apply convolution with kernel A\n",
        "kernel_image_A = ICV_convolution(image, kernel_A)\n",
        "cv2.imwrite('kernel_A.jpg', kernel_image_A)\n",
        "\n",
        "# Apply convolution with kernel B\n",
        "kernel_image_B = ICV_convolution(image, kernel_B)\n",
        "cv2.imwrite('kernel_B.jpg', kernel_image_B)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Tihkqebwtby7",
      "metadata": {
        "id": "Tihkqebwtby7"
      },
      "source": [
        "d) Use the filtering function for the following filtering operations: (i) A followed by A; (ii) A followed by B;\n",
        "(iii) B followed by A. Comment the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FCaVoS8btnwX",
      "metadata": {
        "id": "FCaVoS8btnwX"
      },
      "outputs": [],
      "source": [
        "# (i) A followed by A\n",
        "kernel_AA = ICV_convolution(image, kernel_A)\n",
        "kernel_AA = ICV_convolution(kernel_AA, kernel_A)\n",
        "cv2.imwrite('kernel_AA.jpg', kernel_AA)\n",
        "\n",
        "# (ii) A followed by B\n",
        "kernel_AB = ICV_convolution(image, kernel_A)\n",
        "kernel_AB = ICV_convolution(kernel_AB, kernel_B)\n",
        "cv2.imwrite('kernel_AB.jpg', kernel_AB)\n",
        "\n",
        "# (iii) B followed by A\n",
        "kernel_BA = ICV_convolution(image, kernel_B)\n",
        "kernel_BA = ICV_convolution(kernel_BA, kernel_A)\n",
        "cv2.imwrite('kernel_BA.jpg', kernel_BA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RkFXbz8ZXyFX",
      "metadata": {
        "id": "RkFXbz8ZXyFX"
      },
      "source": [
        "Video Segmentation. (Use Dataset B)\n",
        "A colour histogram h(.) can be generated by counting how many times each colour occurs in an image.\n",
        "Histogram intersection can be used to match a pair of histograms. Given a pair of histograms, e.g., of an\n",
        "input image I and a model M, each containing n bins, the intersection of the histograms is defined as\n",
        "∑ min[h(Ij), h(Mj)]\n",
        "n\n",
        "j=1\n",
        ".\n",
        "\n",
        "a) Write a histogram function that returns the colour histogram of an input image. Visualize the histogram\n",
        "and save the corresponding figure. For a given video sequence, use the above function to construct\n",
        "the histogram of each frame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SKTkbsaG8Flu",
      "metadata": {
        "id": "SKTkbsaG8Flu"
      },
      "outputs": [],
      "source": [
        "def ICV_histogram(image):\n",
        "    h_bins = 256\n",
        "    hist = [np.zeros(h_bins), np.zeros(h_bins), np.zeros(h_bins)]\n",
        "    for i in range(image.shape[0]):\n",
        "        for j in range(image.shape[1]):\n",
        "            hist[0][image[i, j, 0]] += 1\n",
        "            hist[1][image[i, j, 1]] += 1\n",
        "            hist[2][image[i, j, 2]] += 1\n",
        "    return hist\n",
        "\n",
        "def ICV_histogram_with_frame(frame, hist, frame_idx, filename=None):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot the frame\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(frame)\n",
        "    plt.title(f'Frame {frame_idx}')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Plot the histogram\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(f'Histogram for Frame {frame_idx}')\n",
        "    plt.xlabel('Bins')\n",
        "    plt.ylabel('Pixels')\n",
        "    colors = ('r', 'g', 'b')\n",
        "    for i, color in enumerate(colors):\n",
        "        plt.plot(hist[i], color=color)\n",
        "        plt.xlim([0, 256])\n",
        "\n",
        "    if filename:\n",
        "        plt.savefig(filename)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "def ICV_process_all_frames(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = {}\n",
        "    histograms = {}\n",
        "\n",
        "    frame_idx = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        hist = ICV_histogram(frame_rgb)\n",
        "        frames[frame_idx] = frame_rgb\n",
        "        histograms[frame_idx] = hist\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    return frames, histograms\n",
        "\n",
        "# Process and store all frames and histograms\n",
        "frames, histograms = ICV_process_all_frames('DatasetB.avi')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ZDt_MEI86rG",
      "metadata": {
        "id": "6ZDt_MEI86rG"
      },
      "outputs": [],
      "source": [
        "#Display the selected frame along with histogram\n",
        "ICV_histogram_with_frame(frames[11], histograms[11], 11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "svE6f6GiKy8X",
      "metadata": {
        "id": "svE6f6GiKy8X"
      },
      "outputs": [],
      "source": [
        "ICV_histogram_with_frame(frames[100], histograms[100], 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "URkZd4Pvc4Wr",
      "metadata": {
        "id": "URkZd4Pvc4Wr"
      },
      "source": [
        "Write a function that returns the value of the intersection of a pair of histograms. For a given video\n",
        "sequence, use the histogram intersection function to calculate the intersection between consecutive\n",
        "frames (e.g. between It and It+1, between It+1 and It+2 and so on). Find how to normalize the\n",
        "intersection. Does that change the results? Plot the intersection values over time and the normalised\n",
        "intersection values, and save the corresponding figures. Show and comment the figures in the report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tYFkT8GQQDtE",
      "metadata": {
        "id": "tYFkT8GQQDtE"
      },
      "outputs": [],
      "source": [
        "# Process and store all frames and histograms\n",
        "def ICV_histogram_intersection(hist1, hist2):\n",
        "    intersection = 0\n",
        "    for channel in range(3):\n",
        "        intersection += np.sum(np.minimum(hist1[channel], hist2[channel]))\n",
        "    return intersection\n",
        "\n",
        "# Function to plot the overall histogram intersection for two specific frames\n",
        "def ICV_plot_histogram_intersections(frame_idx, histograms, filename):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    colors = ['r', 'g', 'b']\n",
        "    for channel in range(3):\n",
        "        plt.subplot(1, 3, channel+1)\n",
        "        plt.bar(range(256), np.minimum(histograms[frame_idx][channel], histograms[frame_idx+1][channel]), color=colors[channel], alpha=0.7)\n",
        "        plt.title(f'Intersection {colors[channel].upper()} Channel')\n",
        "        plt.xlabel('Bin')\n",
        "        plt.ylabel('Frequency')\n",
        "    plt.suptitle(f'Histogram Intersections: Frames {frame_idx} and {frame_idx+1}')\n",
        "    plt.savefig(filename)\n",
        "    plt.show()\n",
        "ICV_histogram_with_frame(frames[300], histograms[300], 300)\n",
        "ICV_histogram_with_frame(frames[301], histograms[301], 301)\n",
        "# Plot histogram intersections for specific frames\n",
        "ICV_plot_histogram_intersections(300, histograms, 'pair_histogram_intersection.png')\n",
        "\n",
        "\n",
        "# Calculate intersection values for the entire video sequence\n",
        "intersection_values = []\n",
        "normalized_intersection_values = []\n",
        "for i in range(len(histograms) - 1):\n",
        "    intersection = ICV_histogram_intersection(histograms[i], histograms[i+1])\n",
        "    intersection_values.append(intersection)\n",
        "    total_count = sum([np.sum(histograms[i][channel]) for channel in range(3)])\n",
        "    normalized = intersection / total_count\n",
        "    normalized_intersection_values.append(normalized)\n",
        "\n",
        "# Plotting function for raw and normalized intersection values\n",
        "def plot_intersection(values, title, filename):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(values)\n",
        "    plt.xlabel('Frame Index')\n",
        "    plt.ylabel('Intersection Value')\n",
        "    plt.title(title)\n",
        "    plt.savefig(filename)\n",
        "    plt.show()\n",
        "\n",
        "# Plot and save the raw intersection values\n",
        "plot_intersection(intersection_values, 'Raw Histogram Intersection', 'raw_intersection_video.png')\n",
        "\n",
        "# Plot and save the normalized intersection values\n",
        "plot_intersection(normalized_intersection_values, 'Normalized Histogram Intersection ', 'normalized_intersection_video.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1msjNAOsEiEt",
      "metadata": {
        "id": "1msjNAOsEiEt"
      },
      "source": [
        "4) Texture Classification. (Use Datasets A and B)\n",
        "The Local Binary Pattern (LBP) operator describes the surroundings of a pixel by generating a bit-code\n",
        "from the binary derivatives of a pixel.\n",
        "\n",
        "a) Write a function that divides a greyscale image into equally sized non-overlapping windows and\n",
        "returns the feature descriptor for each window as distribution of LBP codes. For each pixel in the\n",
        "window, compare the pixel to each of its 8 neighbours. Convert the resulting bit-codes (base 2) to\n",
        "decimals (base 10 numbers) and compute their histogram over the window. Normalize the histogram\n",
        "(which is now a feature descriptor representing the window). Show in the report the resulting images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3r0Qy1SCY6Zx",
      "metadata": {
        "id": "3r0Qy1SCY6Zx"
      },
      "outputs": [],
      "source": [
        "def ICV_lbp(image, window_size):\n",
        "    \"\"\"\n",
        "    This function divides the image into non-overlapping windows,\n",
        "    applies the LBP operation on each window, and computes the normalized\n",
        "    histogram of LBP codes for each window.\n",
        "    \"\"\"\n",
        "    rows, cols = image.shape\n",
        "    lbp_image = np.zeros_like(image, dtype=np.uint8)\n",
        "    # Determine the number of windows in each dimension\n",
        "    num_windows_x = cols // window_size\n",
        "    num_windows_y = rows // window_size\n",
        "    # a list histograms for each window\n",
        "    histograms = []\n",
        "    # Process each window\n",
        "    for win_y in range(0, rows - window_size + 1, window_size):\n",
        "        for win_x in range(0, cols - window_size + 1, window_size):\n",
        "            window = image[win_y:win_y + window_size, win_x:win_x + window_size]\n",
        "            lbp_window = np.zeros_like(window, dtype=np.uint8)\n",
        "\n",
        "            # LBP operation per window\n",
        "            for i in range(1, window_size - 1):\n",
        "                for j in range(1, window_size - 1):\n",
        "                    center = window[i, j]\n",
        "                    binary_str = ''\n",
        "                    # Compare with the 8 neighbors to create the binary string\n",
        "                    for dy, dx in [(-1, -1), (-1, 0), (-1, 1),\n",
        "                                   (0, 1), (1, 1), (1, 0),\n",
        "                                   (1, -1), (0, -1)]:\n",
        "                        binary_str += '1' if window[i + dy, j + dx] > center else '0'\n",
        "\n",
        "                    lbp_window[i, j] = int(binary_str, 2)\n",
        "\n",
        "            # Update the LBP image\n",
        "            lbp_image[win_y:win_y + window_size, win_x:win_x + window_size] = lbp_window\n",
        "\n",
        "            # Calculate and normalize histogram for the window\n",
        "            hist, _ = np.histogram(lbp_window.ravel(), bins=np.arange(257), range=(0, 256))\n",
        "            hist = hist.astype(\"float\")\n",
        "            hist /= hist.sum()\n",
        "            histograms.append(hist)\n",
        "    return histograms, lbp_image\n",
        "\n",
        "window_size = 32\n",
        "img = cv2.imread('car-1.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "# Compute the LBP for windowed image\n",
        "histograms, lbp_img = ICV_lbp(img, window_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hWVKmdr2s-Lg",
      "metadata": {
        "id": "hWVKmdr2s-Lg"
      },
      "outputs": [],
      "source": [
        "def ICV_visualize_selected_windows(image, lbp_image, histograms, window_size, selected_indices):\n",
        "    for idx in selected_indices:\n",
        "        # Calculate the position of the window\n",
        "        num_windows_x = image.shape[1] // window_size\n",
        "        x = (idx % num_windows_x) * window_size\n",
        "        y = (idx // num_windows_x) * window_size\n",
        "\n",
        "        # Extract the window from the original and LBP images\n",
        "        window = image[y:y + window_size, x:x + window_size]\n",
        "        lbp_window = lbp_image[y:y + window_size, x:x + window_size]\n",
        "\n",
        "        # Display the original window\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(window, cmap='gray')\n",
        "        plt.title(f'Original Window {idx+1}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Display the LBP of the window\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(lbp_window, cmap='gray')\n",
        "        plt.title(f'LBP Window {idx+1}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Display the histogram for the window\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.bar(range(256), histograms[idx])\n",
        "        plt.title(f'Normalized LBP Histogram {idx+1}')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "#  window indices\n",
        "selected_indices = [0, 2, 35]\n",
        "ICV_visualize_selected_windows(img, lbp_img, histograms, window_size, selected_indices)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Xk1_ICQVMlIC",
      "metadata": {
        "id": "Xk1_ICQVMlIC"
      },
      "source": [
        "b) Come up with a descriptor that represents the whole image as consisting of multiple windows. For\n",
        "example, you could combine several local descriptions into a global description by concatenation.\n",
        "Discuss in the report alternative approaches. Using the global descriptor you created, implement a\n",
        "classification process that separates the images in the dataset into two categories: face images and\n",
        "non-face images (for example, you could use histogram similarities). Comment the results in the\n",
        "report. Is the global descriptor able to represent whole images of different types (e.g. faces vs. cars)?\n",
        "Identify problems (if any), discuss them in the report and suggest possible solutions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jGWDH-dyshcb",
      "metadata": {
        "id": "jGWDH-dyshcb"
      },
      "outputs": [],
      "source": [
        "#Calculate the Euclidean distance between two histograms\n",
        "def ICV_euclidean_distance(hist1, hist2):\n",
        "    return np.sqrt(np.sum((hist1 - hist2) ** 2))\n",
        "\n",
        "def ICV_classify_image(test_image, training_images, training_labels, window_size):\n",
        "    # Compute the histogram of the test image using\n",
        "    test_histograms, _ = ICV_lbp(test_image, window_size)\n",
        "    # Concatenate histograms to create a descriptor for the test image\n",
        "    test_descriptor = np.concatenate(test_histograms)\n",
        "\n",
        "    nearest_label = None\n",
        "    min_distance = float('inf')\n",
        "    # Compare the test image descriptor with each training image descriptor\n",
        "    for train_image, label in zip(training_images, training_labels):\n",
        "        train_histograms, _ = ICV_lbp(train_image, window_size)\n",
        "        train_descriptor = np.concatenate(train_histograms)\n",
        "        # Calculate the Euclidean distance between descriptors\n",
        "        distance = ICV_euclidean_distance(test_descriptor, train_descriptor)\n",
        "\n",
        "        if distance < min_distance:\n",
        "            min_distance = distance\n",
        "            nearest_label = label\n",
        "\n",
        "    return nearest_label,test_descriptor\n",
        "\n",
        "# Reading the images in grayscale\n",
        "car = cv2.imread('car-1.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "car2 = cv2.imread('car-2.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "face = cv2.imread('face-1.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "face2 = cv2.imread('face-2.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "test_face = cv2.imread('face-3.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "test_car = cv2.imread('car-3.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "training_images = [car, car2, face, face2]\n",
        "training_labels = ['non-face', 'non-face', 'face', 'face']\n",
        "\n",
        "window_size=50\n",
        "# Classifying test images\n",
        "car_test,test_descriptor = ICV_classify_image(test_car, training_images, training_labels, window_size)\n",
        "face_test,test_descriptor2 = ICV_classify_image(test_face, training_images, training_labels, window_size)\n",
        "# Printing results\n",
        "print(\"Car test lebel:\",car_test)\n",
        "print(\"Face test lebel:\",face_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fF9rl70b264b",
      "metadata": {
        "id": "fF9rl70b264b"
      },
      "outputs": [],
      "source": [
        "def ICV_plot_descriptor_histogram(descriptor, title=\"Descriptor Histogram\"):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.bar(range(len(descriptor)), descriptor, width=1.0)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Descriptor Bin')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95UJmcm45wpN",
      "metadata": {
        "id": "95UJmcm45wpN"
      },
      "outputs": [],
      "source": [
        "ICV_plot_descriptor_histogram(test_descriptor, \"Test car descriptor histogram\")\n",
        "ICV_plot_descriptor_histogram(test_descriptor2, \"Test face descriptor histogram\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rduawirK4R4x",
      "metadata": {
        "id": "rduawirK4R4x"
      },
      "source": [
        "c) Decrease the window size and perform classification again. Comment the results in the report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sakV76tI4Vsf",
      "metadata": {
        "id": "sakV76tI4Vsf"
      },
      "outputs": [],
      "source": [
        "# Decreased window size\n",
        "window_size = 30\n",
        "\n",
        "# Classifying test images with the new window size\n",
        "car_test1, test_descriptor3 = ICV_classify_image(test_car, training_images, training_labels, window_size)\n",
        "face_test1, test_descriptor4 = ICV_classify_image(test_face, training_images, training_labels, window_size)\n",
        "\n",
        "# Printing results\n",
        "print(\"Car test label:\", car_test1)\n",
        "print(\"Face test label:\", face_test1)\n",
        "\n",
        "# Plotting descriptor histograms for the test images\n",
        "ICV_plot_descriptor_histogram(test_descriptor3, \"Test car descriptor histogram\")\n",
        "ICV_plot_descriptor_histogram(test_descriptor4, \"Test face descriptor histogram\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5b9AiJ54WnW",
      "metadata": {
        "id": "a5b9AiJ54WnW"
      },
      "source": [
        "d) Increase the window size and perform classification again. Comment the results in the report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FHj8zare4Zvn",
      "metadata": {
        "id": "FHj8zare4Zvn"
      },
      "outputs": [],
      "source": [
        "# Decreased window size\n",
        "window_size = 100\n",
        "\n",
        "# Classifying test images with the new window size\n",
        "car_test2, test_descriptor5 = ICV_classify_image(test_car, training_images, training_labels, window_size)\n",
        "face_test2, test_descriptor6 = ICV_classify_image(test_face, training_images, training_labels, window_size)\n",
        "\n",
        "# Printing results\n",
        "print(\"Car test label:\", car_test2)\n",
        "print(\"Face test label:\", face_test2)\n",
        "\n",
        "# Plotting descriptor histograms for the test images\n",
        "ICV_plot_descriptor_histogram(test_descriptor5, \"Test car descriptor histogram\")\n",
        "ICV_plot_descriptor_histogram(test_descriptor6, \"Test face descriptor histogram\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xHQfu5JK4ah5",
      "metadata": {
        "id": "xHQfu5JK4ah5"
      },
      "source": [
        "e) Discuss how LBP can be used or modified for the analysis of dynamic textures in a video."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nreCBsmE4m8I",
      "metadata": {
        "id": "nreCBsmE4m8I"
      },
      "source": [
        "Moving objects captured by fixed cameras are the focus of several computer vision applications.\n",
        "\n",
        "a) Write a function that performs pixel-by-pixel frame differencing using, as reference frame, the first\n",
        "frame of an image sequence. Apply a classification threshold and save the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G6TWp5hPHsmr",
      "metadata": {
        "id": "G6TWp5hPHsmr"
      },
      "outputs": [],
      "source": [
        "def ICV_pixel_thresholding(frame, threshold):\n",
        "    \"\"\"\n",
        "    Apply thresholding to a frame pixel by pixel.\n",
        "    :param frame: Grayscale image frame.\n",
        "    :param threshold: Threshold value.\n",
        "    :return: Thresholded frame.\n",
        "    \"\"\"\n",
        "    height, width = frame.shape\n",
        "    thresholded = np.zeros((height, width), dtype=np.uint8)\n",
        "\n",
        "    for h in range(height):\n",
        "        for w in range(width):\n",
        "            thresholded[h, w] = 255 if frame[h, w] > threshold else 0\n",
        "\n",
        "    return thresholded\n",
        "\n",
        "def ICV_frame_difference(reference, current):\n",
        "    \"\"\"\n",
        "    Compute the absolute difference between two frames pixel by pixel.\n",
        "    Stores the original frames, frame differencing results, and threshold results in dictionaries.\n",
        "    :param reference: Reference grayscale frame.\n",
        "    :param current: Current grayscale frame.\n",
        "    \"\"\"\n",
        "    height, width = reference.shape\n",
        "    diff_frame = np.zeros((height, width), dtype=np.uint8)\n",
        "\n",
        "    for i in range(height):\n",
        "        for j in range(width):\n",
        "            diff = abs(int(current[i, j]) - int(reference[i, j]))\n",
        "            diff_frame[i, j] = diff\n",
        "\n",
        "    return diff_frame\n",
        "\n",
        "def ICV_process_video(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Read the first frame as the reference frame\n",
        "    _, reference_frame = cap.read()\n",
        "    reference_frame_gray = cv2.cvtColor(reference_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Dictionaries to store frames, differences, and thresholds\n",
        "    frames, differencing, thresholded = {}, {}, {}\n",
        "\n",
        "    frame_count = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        current_frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Compute the absolute difference and apply threshold\n",
        "        difference_frame = ICV_frame_difference(reference_frame_gray, current_frame_gray)\n",
        "        thresholded_frame = ICV_pixel_thresholding(difference_frame, 30)\n",
        "\n",
        "        # Store frames and results\n",
        "        frames[frame_count] = current_frame_gray\n",
        "        differencing[frame_count] = difference_frame\n",
        "        thresholded[frame_count] = thresholded_frame\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    return frames, differencing, thresholded, reference_frame_gray\n",
        "\n",
        "# Processing the video\n",
        "video_path = 'DatasetC.avi'\n",
        "frames, diff, thresholded, reference_frame_gray = ICV_process_video(video_path)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "# Display the reference frame\n",
        "plt.subplot(3, 4, 1)\n",
        "plt.imshow(reference_frame_gray, cmap='gray')\n",
        "plt.title(\"Reference Frame\")\n",
        "\n",
        "indices_to_display = [10, 100]\n",
        "\n",
        "for i, idx in enumerate(indices_to_display):\n",
        "    # Original Frame\n",
        "    plt.subplot(3, 4, i * 4 + 2)\n",
        "    plt.imshow(frames[idx], cmap='gray')\n",
        "    plt.title(f\"Original Frame {idx}\")\n",
        "\n",
        "    # Difference Frame\n",
        "    plt.subplot(3, 4, i * 4 + 3)\n",
        "    plt.imshow(diff[idx], cmap='gray')\n",
        "    plt.title(f\"Diff Frame {idx}\")\n",
        "\n",
        "    # Thresholded Frame\n",
        "    plt.subplot(3, 4, i * 4 + 4)\n",
        "    plt.imshow(thresholded[idx], cmap='gray')\n",
        "    plt.title(f\"Threshold Frame {idx}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1YE_JuZu4o7e",
      "metadata": {
        "id": "1YE_JuZu4o7e"
      },
      "source": [
        "b) Repeat the exercise using the previous frame as reference frame (use frame It-1 as reference frame\n",
        "for frame It, for each t). Comment the results in the report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GdtiZTjCJvqa",
      "metadata": {
        "id": "GdtiZTjCJvqa"
      },
      "outputs": [],
      "source": [
        "def ICV_frame_differencing(video_path, threshold):\n",
        "    \"\"\"\n",
        "    Performs frame differencing using the previous frame as reference.\n",
        "    Stores the original frames, frame differencing results, and threshold results in dictionaries.\n",
        "\n",
        "    :param video_path: Path to the input video file.\n",
        "    :param threshold: Classification threshold for differencing.\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Check if the video is opened successfully\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error opening video file\")\n",
        "        return\n",
        "\n",
        "    # Initialize dictionaries to store frames, differences, and thresholds\n",
        "    frames, diffs, thresholds = {}, {}, {}\n",
        "\n",
        "    # Read the first frame and set it as the previous frame\n",
        "    ret, prev_frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Failed to read the video.\")\n",
        "        return\n",
        "\n",
        "    prev_frame_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
        "    frame_count = 0\n",
        "\n",
        "    while True:\n",
        "        ret, current_frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Convert current frame to grayscale\n",
        "        current_frame_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Compute the absolute difference\n",
        "        diff = ICV_frame_difference(prev_frame_gray, current_frame_gray)\n",
        "\n",
        "        # Apply threshold\n",
        "        thresh = ICV_pixel_thresholding(diff, threshold)\n",
        "\n",
        "        # Store the frames, differences, and thresholds\n",
        "        frames[frame_count] = current_frame_gray\n",
        "        diffs[frame_count] = diff\n",
        "        thresholds[frame_count] = thresh\n",
        "\n",
        "        # Update the previous frame\n",
        "        prev_frame_gray = current_frame_gray\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    return frames, diffs, thresholds\n",
        "\n",
        "video_path = 'DatasetC.avi'\n",
        "threshold = 50\n",
        "frames, diffs, thresholds = ICV_frame_differencing(video_path, threshold)\n",
        "\n",
        "# Displaying selected frames along with their difference and thresholded frames\n",
        "plt.figure(figsize=(12, 8))\n",
        "# Select indices to display\n",
        "indices_to_display = [10, 100]\n",
        "\n",
        "for i, idx in enumerate(indices_to_display):\n",
        "    # Original Frame\n",
        "    plt.subplot(3, 3, i * 3 + 1)\n",
        "    plt.imshow(frames[idx], cmap='gray')\n",
        "    plt.title(f\"Original Frame {idx}\")\n",
        "\n",
        "    # Difference Frame\n",
        "    plt.subplot(3, 3, i * 3 + 2)\n",
        "    plt.imshow(diffs[idx], cmap='gray')\n",
        "    plt.title(f\"Diff Frame {idx}\")\n",
        "\n",
        "    # Thresholded Frame\n",
        "    plt.subplot(3, 3, i * 3 + 3)\n",
        "    plt.imshow(thresholds[idx], cmap='gray')\n",
        "    plt.title(f\"Threshold Frame {idx}\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caIpDEyf4uQ3",
      "metadata": {
        "id": "caIpDEyf4uQ3"
      },
      "source": [
        "c) Write a function that generates a reference frame (background) for the sequence using for example\n",
        "frame differencing and a weighted temporal averaging algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y21twOZ2JeV8",
      "metadata": {
        "id": "y21twOZ2JeV8"
      },
      "outputs": [],
      "source": [
        "def ICV_weighted_average(background, current_frame, alpha):\n",
        "    # Apply temporal weighting to update the background\n",
        "    return (1 - alpha) * background + alpha * current_frame\n",
        "\n",
        "def ICV_background(video_path, base_alpha=0.01, max_alpha=0.1, threshold=10, movement_threshold=50):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error opening video stream or file\")\n",
        "        return None\n",
        "\n",
        "    ret, background_frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Could not read the first frame.\")\n",
        "        cap.release()\n",
        "        return None\n",
        "\n",
        "    # Initialize the background\n",
        "    background = cv2.cvtColor(background_frame, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
        "    prev_frame = background.copy()\n",
        "\n",
        "    while True:\n",
        "        ret, current_frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        current_frame_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
        "        # Compute the frame difference with the previous frame\n",
        "        diff = ICV_frame_difference(prev_frame, current_frame_gray)\n",
        "\n",
        "        # Apply thresholding to get the moving objects mask\n",
        "        movement = ICV_pixel_thresholding(diff, movement_threshold)\n",
        "\n",
        "        # Invert the mask background areas are 1 moving objects are 0\n",
        "        background_mask = 1 - (movement / 255).astype(np.float32)\n",
        "\n",
        "        # Calculate dynamic alpha for background areas\n",
        "        alpha = ICV_weighted_average(base_alpha, max_alpha, background_mask)\n",
        "\n",
        "        # Update the background only where there is no movement\n",
        "        background = (1 - alpha) * background + alpha * current_frame_gray * background_mask\n",
        "\n",
        "        prev_frame = current_frame_gray\n",
        "\n",
        "    cap.release()\n",
        "    return background.astype(np.uint8)\n",
        "\n",
        "video_path = 'DatasetC.avi'\n",
        "background = ICV_background(video_path)\n",
        "\n",
        "# Save the generated reference frame\n",
        "cv2.imwrite(\"background.png\", background)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}